{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dic/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out,name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        w=tf.Variable(tf.truncated_normal([5,5,channels_in,channels_out], stddev=0.1),name=\"W\")\n",
    "        #initializer=tf.glorot_uniform_initializer()\n",
    "        #,initializer=tf.truncated_normal_initializer(stddev=0.05)\n",
    "        b=tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"B\")\n",
    "        #,initializer=tf.random_uniform_initializer(-0.1,0.1)\n",
    "        \n",
    "        conv=tf.nn.conv2d(input,w, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        act=tf.nn.relu(conv+b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "def dense_layer(input, channels_in, channels_out,name=\"dense\"):\n",
    "    with tf.name_scope(name):\n",
    "        w=tf.Variable(tf.truncated_normal([channels_in,channels_out], stddev=0.1),name=\"W\")\n",
    "        b=tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"B\")\n",
    "        act=tf.nn.relu(tf.matmul(input, w)+b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup placeholders\n",
    "x= tf.placeholder(tf.float32, shape=[None,28,28,1],name=\"x\")#here None will take input at the time of training and it will take the value equal to the batch size \n",
    "y= tf.placeholder(tf.float32, shape=[None,7],name=\"labels\")\n",
    "\n",
    "\n",
    "#Creating the network\n",
    "\n",
    "#def conv_net(x):\n",
    "conv1=conv_layer(x, 1, 32,\"conv1\")\n",
    "drop1=tf.nn.dropout(conv1,keep_prob=0.1,name=\"dropout1\")\n",
    "flattened = tf.reshape(drop1, [-1, 28 * 28 * 32])\n",
    "\n",
    "dense1=dense_layer(flattened,28*28*32,128,\"dense1\")\n",
    "drop2=tf.nn.dropout(dense1,keep_prob=0.25,name=\"dropout2\")\n",
    "dense2=dense_layer(drop2,128,128,\"dense2\")\n",
    "logits=dense_layer(dense2,128,7,\"dense3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-59add52ab621>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pred = conv_net(x)\n",
    "\n",
    "#cross entropy as loss function\n",
    "#cost=tf.reduce_mean=(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    tf.summary.scalar(\"Loss\", cost)\n",
    "#adamoptimizer\n",
    "#optimizer=tf.train.AdamOptimizer(0.0002).minimize(cost)\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(cost)\n",
    "    \n",
    "#computing accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "\n",
    "    #calculate accuracy across all the given images and average them out. \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36504, 7)\n",
      "(36504, 28, 28, 1)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "(36504, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import tensorflow.contrib.eager as tfe\n",
    "# Load the training data into two NumPy arrays.\n",
    "\n",
    "classes=7\n",
    "features = np.load(\"X_2d.npy\")\n",
    "labels = np.load(\"y_onehot.npy\")\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(features, labels, test_size=0.2, random_state=1, shuffle=True)\n",
    "print(y_train1.shape)\n",
    "X_train = X_train1.reshape(-1, 28, 28, 1)\n",
    "X_test= X_test1.reshape(-1,28,28,1)\n",
    "y_train=y_train1.reshape(-1,7)\n",
    "y_test=y_test1.reshape(-1,7)\n",
    "print(X_train.shape)\n",
    "print(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "epoch=200\n",
    "batch_size=200\n",
    "steps=int(len(X_train)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_1 = tf.summary.FileWriter(\"/home/dic/jupyter/28x28dmdt/log_dir/train_1_200epochs_1\")\n",
    "#writer_2 = tf.summary.FileWriter(\"/home/dic/jupyter/28x28dmdt/log_dir/test_1_200epochs\")\n",
    "writer_1.add_graph(sess.graph)\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss=  1.9535632 , Training Accuracy=  0.62\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.62656146\n",
      "Iter 1, Loss=  1.7061777 , Training Accuracy=  0.625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6493535\n",
      "Iter 2, Loss=  1.7118776 , Training Accuracy=  0.635\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6551611\n",
      "Iter 3, Loss=  1.6217933 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.65976334\n",
      "Iter 4, Loss=  1.4778092 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.662174\n",
      "Iter 5, Loss=  1.4164929 , Training Accuracy=  0.64\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66294104\n",
      "Iter 6, Loss=  1.3752381 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6640368\n",
      "Iter 7, Loss=  1.364556 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6631602\n",
      "Iter 8, Loss=  1.2972571 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66392726\n",
      "Iter 9, Loss=  1.2981563 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66381764\n",
      "Iter 10, Loss=  1.2917804 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6640368\n",
      "Iter 11, Loss=  1.3044255 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66392726\n",
      "Iter 12, Loss=  1.2905922 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66436553\n",
      "Iter 13, Loss=  1.2857205 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66392726\n",
      "Iter 14, Loss=  1.268783 , Training Accuracy=  0.65\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.664256\n",
      "Iter 15, Loss=  1.2453989 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66359854\n",
      "Iter 16, Loss=  1.2302196 , Training Accuracy=  0.65\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6641464\n",
      "Iter 17, Loss=  1.2816131 , Training Accuracy=  0.64\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6661188\n",
      "Iter 18, Loss=  1.2558072 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6669954\n",
      "Iter 19, Loss=  1.2063193 , Training Accuracy=  0.66\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.66710496\n",
      "Iter 20, Loss=  1.1896785 , Training Accuracy=  0.63\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6711593\n",
      "Iter 21, Loss=  1.134502 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6703923\n",
      "Iter 22, Loss=  1.1652532 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.67203593\n",
      "Iter 23, Loss=  1.1742893 , Training Accuracy=  0.64\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.67181677\n",
      "Iter 24, Loss=  1.199608 , Training Accuracy=  0.65\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6713785\n",
      "Iter 25, Loss=  1.1333421 , Training Accuracy=  0.65\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.67357004\n",
      "Iter 26, Loss=  1.1179521 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6751041\n",
      "Iter 27, Loss=  1.0895079 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6802542\n",
      "Iter 28, Loss=  1.0243132 , Training Accuracy=  0.67\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6783914\n",
      "Iter 29, Loss=  1.1240873 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6804734\n",
      "Iter 30, Loss=  1.003395 , Training Accuracy=  0.655\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6827745\n",
      "Iter 31, Loss=  1.0430458 , Training Accuracy=  0.67\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.68091166\n",
      "Iter 32, Loss=  1.0093182 , Training Accuracy=  0.675\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6857331\n",
      "Iter 33, Loss=  1.06012 , Training Accuracy=  0.675\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6845277\n",
      "Iter 34, Loss=  0.99795485 , Training Accuracy=  0.655\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6860618\n",
      "Iter 35, Loss=  1.0160589 , Training Accuracy=  0.69\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6893491\n",
      "Iter 36, Loss=  0.9931447 , Training Accuracy=  0.675\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6921981\n",
      "Iter 37, Loss=  1.0033045 , Training Accuracy=  0.685\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6940609\n",
      "Iter 38, Loss=  1.0069923 , Training Accuracy=  0.68\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6960333\n",
      "Iter 39, Loss=  1.0478871 , Training Accuracy=  0.645\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6930747\n",
      "Iter 40, Loss=  0.9800384 , Training Accuracy=  0.655\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.69625247\n",
      "Iter 41, Loss=  1.0142741 , Training Accuracy=  0.665\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.69734824\n",
      "Iter 42, Loss=  1.0093684 , Training Accuracy=  0.69\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.69822484\n",
      "Iter 43, Loss=  0.91140074 , Training Accuracy=  0.7\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7004164\n",
      "Iter 44, Loss=  0.93943113 , Training Accuracy=  0.71\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7027175\n",
      "Iter 45, Loss=  0.9209195 , Training Accuracy=  0.685\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6999781\n",
      "Iter 46, Loss=  0.9134448 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.70348454\n",
      "Iter 47, Loss=  0.94368196 , Training Accuracy=  0.69\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.70797724\n",
      "Iter 48, Loss=  0.9636969 , Training Accuracy=  0.7\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7057857\n",
      "Iter 49, Loss=  0.9780097 , Training Accuracy=  0.68\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.70589525\n",
      "Iter 50, Loss=  0.8974452 , Training Accuracy=  0.7\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.70775807\n",
      "Iter 51, Loss=  0.9044824 , Training Accuracy=  0.69\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.70677185\n",
      "Iter 52, Loss=  0.91357315 , Training Accuracy=  0.69\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7143327\n",
      "Iter 53, Loss=  0.84396964 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.71027833\n",
      "Iter 54, Loss=  0.8671673 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7115933\n",
      "Iter 55, Loss=  0.90986985 , Training Accuracy=  0.685\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.70885384\n",
      "Iter 56, Loss=  0.8170289 , Training Accuracy=  0.72\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7166338\n",
      "Iter 57, Loss=  0.87813586 , Training Accuracy=  0.7\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72003067\n",
      "Iter 58, Loss=  0.8439617 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7169625\n",
      "Iter 59, Loss=  0.8465859 , Training Accuracy=  0.72\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7145518\n",
      "Iter 60, Loss=  0.8720092 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7198115\n",
      "Iter 61, Loss=  0.92069465 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7132369\n",
      "Iter 62, Loss=  0.839068 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.71729124\n",
      "Iter 63, Loss=  0.87061995 , Training Accuracy=  0.685\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7184966\n",
      "Iter 64, Loss=  0.87203646 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72200304\n",
      "Iter 65, Loss=  0.86634505 , Training Accuracy=  0.67\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7203594\n",
      "Iter 66, Loss=  0.83207816 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.71915406\n",
      "Iter 67, Loss=  0.8814648 , Training Accuracy=  0.71\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.723318\n",
      "Iter 68, Loss=  0.8996516 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7237563\n",
      "Iter 69, Loss=  0.82206446 , Training Accuracy=  0.72\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72145516\n",
      "Iter 70, Loss=  0.7939372 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.71970195\n",
      "Iter 71, Loss=  0.849111 , Training Accuracy=  0.7\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72737235\n",
      "Iter 72, Loss=  0.8323705 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72408503\n",
      "Iter 73, Loss=  0.8072316 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7262766\n",
      "Iter 74, Loss=  0.8007225 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72978306\n",
      "Iter 75, Loss=  0.7918347 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7270436\n",
      "Iter 76, Loss=  0.8472826 , Training Accuracy=  0.69\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7284681\n",
      "Iter 77, Loss=  0.79234153 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73208416\n",
      "Iter 78, Loss=  0.7829814 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.73208416\n",
      "Iter 79, Loss=  0.87164277 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7293447\n",
      "Iter 80, Loss=  0.8332626 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72824895\n",
      "Iter 81, Loss=  0.75853956 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7323033\n",
      "Iter 82, Loss=  0.78958017 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73033094\n",
      "Iter 83, Loss=  0.8378336 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73471403\n",
      "Iter 84, Loss=  0.8572544 , Training Accuracy=  0.71\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.72967345\n",
      "Iter 85, Loss=  0.80998504 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73120755\n",
      "Iter 86, Loss=  0.8177672 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7307692\n",
      "Iter 87, Loss=  0.7605806 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7337278\n",
      "Iter 88, Loss=  0.799596 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73471403\n",
      "Iter 89, Loss=  0.76464003 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73405653\n",
      "Iter 90, Loss=  0.7840477 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7358098\n",
      "Iter 91, Loss=  0.78014135 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73646724\n",
      "Iter 92, Loss=  0.8283026 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7371247\n",
      "Iter 93, Loss=  0.8000736 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7374534\n",
      "Iter 94, Loss=  0.7956619 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7371247\n",
      "Iter 95, Loss=  0.7762529 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73876834\n",
      "Iter 96, Loss=  0.7960962 , Training Accuracy=  0.72\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7351523\n",
      "Iter 97, Loss=  0.7952014 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73789173\n",
      "Iter 98, Loss=  0.79320025 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7413982\n",
      "Iter 99, Loss=  0.802412 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74030244\n",
      "Iter 100, Loss=  0.79564255 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74030244\n",
      "Iter 101, Loss=  0.6756916 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7430419\n",
      "Iter 102, Loss=  0.7296184 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7416174\n",
      "Iter 103, Loss=  0.7843994 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74326104\n",
      "Iter 104, Loss=  0.78695333 , Training Accuracy=  0.715\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7452334\n",
      "Iter 105, Loss=  0.82035047 , Training Accuracy=  0.72\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7454526\n",
      "Iter 106, Loss=  0.7128554 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74293226\n",
      "Iter 107, Loss=  0.79171735 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7443568\n",
      "Iter 108, Loss=  0.73589087 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7470962\n",
      "Iter 109, Loss=  0.7192064 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7462196\n",
      "Iter 110, Loss=  0.7781456 , Training Accuracy=  0.7\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74556214\n",
      "Iter 111, Loss=  0.80379903 , Training Accuracy=  0.72\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7468771\n",
      "Iter 112, Loss=  0.7843955 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74786323\n",
      "Iter 113, Loss=  0.7453412 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74402803\n",
      "Iter 114, Loss=  0.7453387 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74797285\n",
      "Iter 115, Loss=  0.71293426 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74731535\n",
      "Iter 116, Loss=  0.7998459 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7452334\n",
      "Iter 117, Loss=  0.7766726 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75202715\n",
      "Iter 118, Loss=  0.77922463 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74884945\n",
      "Iter 119, Loss=  0.72210866 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74884945\n",
      "Iter 120, Loss=  0.78712773 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74884945\n",
      "Iter 121, Loss=  0.7167389 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74589086\n",
      "Iter 122, Loss=  0.7507833 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7496165\n",
      "Iter 123, Loss=  0.6851626 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75597197\n",
      "Iter 124, Loss=  0.7637184 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75465703\n",
      "Iter 125, Loss=  0.6833508 , Training Accuracy=  0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7576156\n",
      "Iter 126, Loss=  0.7198492 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74972606\n",
      "Iter 127, Loss=  0.64485335 , Training Accuracy=  0.78\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7519176\n",
      "Iter 128, Loss=  0.6985123 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.751041\n",
      "Iter 129, Loss=  0.6849585 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7500548\n",
      "Iter 130, Loss=  0.6938825 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7508218\n",
      "Iter 131, Loss=  0.77582914 , Training Accuracy=  0.725\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76177955\n",
      "Iter 132, Loss=  0.73606646 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75641024\n",
      "Iter 133, Loss=  0.77385366 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7599167\n",
      "Iter 134, Loss=  0.67639375 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7552049\n",
      "Iter 135, Loss=  0.78834397 , Training Accuracy=  0.705\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75641024\n",
      "Iter 136, Loss=  0.68828744 , Training Accuracy=  0.79\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7566294\n",
      "Iter 137, Loss=  0.7837693 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7569581\n",
      "Iter 138, Loss=  0.724917 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7615604\n",
      "Iter 139, Loss=  0.7220467 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7613412\n",
      "Iter 140, Loss=  0.72300005 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.759588\n",
      "Iter 141, Loss=  0.70532346 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7604646\n",
      "Iter 142, Loss=  0.71135414 , Training Accuracy=  0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7614508\n",
      "Iter 143, Loss=  0.69269043 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76528597\n",
      "Iter 144, Loss=  0.6727927 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75849223\n",
      "Iter 145, Loss=  0.6979568 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76353276\n",
      "Iter 146, Loss=  0.67080575 , Training Accuracy=  0.78\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7637519\n",
      "Iter 147, Loss=  0.71534806 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7618891\n",
      "Iter 148, Loss=  0.7881358 , Training Accuracy=  0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.764519\n",
      "Iter 149, Loss=  0.6942702 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7607933\n",
      "Iter 150, Loss=  0.67621523 , Training Accuracy=  0.78\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76703924\n",
      "Iter 151, Loss=  0.7147893 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76824456\n",
      "Iter 152, Loss=  0.7085466 , Training Accuracy=  0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76495725\n",
      "Iter 153, Loss=  0.73337466 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76616263\n",
      "Iter 154, Loss=  0.73201996 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7599167\n",
      "Iter 155, Loss=  0.6653267 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7639711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 156, Loss=  0.7000431 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7648477\n",
      "Iter 157, Loss=  0.69563127 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7648477\n",
      "Iter 158, Loss=  0.6755744 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7671488\n",
      "Iter 159, Loss=  0.68751246 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76846373\n",
      "Iter 160, Loss=  0.70569944 , Training Accuracy=  0.785\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77021694\n",
      "Iter 161, Loss=  0.7380208 , Training Accuracy=  0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7718606\n",
      "Iter 162, Loss=  0.7302742 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7686829\n",
      "Iter 163, Loss=  0.7025138 , Training Accuracy=  0.78\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76912117\n",
      "Iter 164, Loss=  0.6572162 , Training Accuracy=  0.805\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76594347\n",
      "Iter 165, Loss=  0.7054357 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7715319\n",
      "Iter 166, Loss=  0.6811815 , Training Accuracy=  0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77361387\n",
      "Iter 167, Loss=  0.72400314 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7669296\n",
      "Iter 168, Loss=  0.7188084 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77032655\n",
      "Iter 169, Loss=  0.7083464 , Training Accuracy=  0.75\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.768135\n",
      "Iter 170, Loss=  0.67697495 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77229893\n",
      "Iter 171, Loss=  0.6858532 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7733947\n",
      "Iter 172, Loss=  0.67216814 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77547663\n",
      "Iter 173, Loss=  0.7266924 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77175105\n",
      "Iter 174, Loss=  0.66086656 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.768135\n",
      "Iter 175, Loss=  0.70662576 , Training Accuracy=  0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7724085\n",
      "Iter 176, Loss=  0.7403457 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7705457\n",
      "Iter 177, Loss=  0.6704189 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.76966906\n",
      "Iter 178, Loss=  0.66840136 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7718606\n",
      "Iter 179, Loss=  0.71066236 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77361387\n",
      "Iter 180, Loss=  0.70757294 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77405214\n",
      "Iter 181, Loss=  0.6714903 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77207977\n",
      "Iter 182, Loss=  0.6581064 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7742713\n",
      "Iter 183, Loss=  0.6739166 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.768135\n",
      "Iter 184, Loss=  0.63807523 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7721894\n",
      "Iter 185, Loss=  0.70172167 , Training Accuracy=  0.745\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77416176\n",
      "Iter 186, Loss=  0.69037414 , Training Accuracy=  0.79\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77175105\n",
      "Iter 187, Loss=  0.6215954 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7725181\n",
      "Iter 188, Loss=  0.6339781 , Training Accuracy=  0.785\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7737234\n",
      "Iter 189, Loss=  0.70984954 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7777778\n",
      "Iter 190, Loss=  0.6566372 , Training Accuracy=  0.795\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.78029805\n",
      "Iter 191, Loss=  0.6588628 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77558625\n",
      "Iter 192, Loss=  0.7413545 , Training Accuracy=  0.755\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7733947\n",
      "Iter 193, Loss=  0.6445909 , Training Accuracy=  0.785\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7771203\n",
      "Iter 194, Loss=  0.64739573 , Training Accuracy=  0.76\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7737234\n",
      "Iter 195, Loss=  0.69226956 , Training Accuracy=  0.785\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7753671\n",
      "Iter 196, Loss=  0.69949484 , Training Accuracy=  0.74\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7824896\n",
      "Iter 197, Loss=  0.69984835 , Training Accuracy=  0.765\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77799696\n",
      "Iter 198, Loss=  0.66868454 , Training Accuracy=  0.73\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7774491\n",
      "Iter 199, Loss=  0.6829422 , Training Accuracy=  0.77\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7713127\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "#writer = tf.summary.FileWriter('/home/dic/jupyter/28x28dmdt/log_dir/1', sess.graph)    \n",
    "    \n",
    "for e in range(epoch):\n",
    "    epoch_loss=0\n",
    "    \n",
    "    for batch in range(steps):\n",
    "        #Calculate our current step\n",
    "        step = e * steps + batch\n",
    "    \n",
    "        batch_x = X_train[batch*batch_size:min((batch+1)*batch_size,len(X_train))]\n",
    "        batch_y = y_train[batch*batch_size:min((batch+1)*batch_size,len(y_train))]\n",
    "        \n",
    "            #batch,c=sess.run([optimizer,loss],feed_dict={x:batch_x,y=batch_y})\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict={x: batch_x,y: batch_y})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,y: batch_y})\n",
    "        if step % 100 == 0:\n",
    "            \n",
    "            # Get Train Summary for one batch and add summary to TensorBoard                                                      \n",
    "            summary = sess.run(write_op,feed_dict={x: batch_x,y: batch_y})\n",
    "            writer_1.add_summary(summary, step)\n",
    "            writer_1.flush()\n",
    "    \n",
    "    print(\"Iter \" + str(e) + \", Loss= \",loss , \", Training Accuracy= \",acc)                                     \n",
    "    print(\"Optimization Finished!\")\n",
    "        \n",
    "       \n",
    "    test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: X_test,y : y_test})\n",
    "    \n",
    "    train_loss.append(loss)\n",
    "    test_loss.append(valid_loss)\n",
    "    train_accuracy.append(acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    #summary1 = sess.run(write_op,feed_dict={x: X_test,y : y_test})\n",
    "    #writer_2.add_summary(summary1)\n",
    "    #writer_2.flush()\n",
    "    print(\"Testing Accuracy:\",test_acc)\n",
    "        #print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
